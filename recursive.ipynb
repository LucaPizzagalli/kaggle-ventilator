{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Kaggle Competition\n","## Google Brain - Ventilator Pressure Prediction\n","### Simulate a ventilator connected to a sedated patient's lung\n","\n","<https://www.kaggle.com/c/ventilator-pressure-prediction>\n","\n","I can take inspiration from <https://www.kaggle.com/yasufuminakama/ventilator-pressure-lstm-starter>\n","\n","## Notes\n","\n","- maybe from test `breath_id` I can infer the type of profile\n","- I can predict in the frequency domain, with a fourier transform"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["\"{'nn_depth': 7, 'layers_width': 80, 'dropout_p': 0.2, 'learning_rate': 0.01, 'batch_size': 64}\""]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["config = {\n","    'nn_depth': 7,\n","    'layers_width': 80,\n","    'dropout_p': 0.2,\n","    'learning_rate': 10e-3,\n","    'batch_size': 64,\n","}\n","f'{config}'"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:25:08.836453Z","iopub.status.busy":"2021-10-11T15:25:08.835839Z","iopub.status.idle":"2021-10-11T15:25:14.482255Z","shell.execute_reply":"2021-10-11T15:25:14.481572Z","shell.execute_reply.started":"2021-10-11T15:25:08.836363Z"},"trusted":true},"outputs":[],"source":["# Basic\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import gzip\n","from pathlib import Path\n","\n","# Preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Clustering\n","from sklearn.cluster import KMeans\n","from sklearn.cluster import DBSCAN\n","from sklearn.decomposition import PCA\n","\n","# Various regressor\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.linear_model import LinearRegression\n","\n","# PyTorch\n","import torch\n","from torch.utils.data import Dataset\n","from torch.utils.data import DataLoader\n","from torch import nn\n","\n","# Hyperparametes optimization\n","from ray import tune\n","from ray.tune import CLIReporter\n","from ray.tune.schedulers import ASHAScheduler\n","\n","# Visualization\n","import ipywidgets\n","import plotly.graph_objects as go\n","from plotly.subplots import make_subplots\n","from torch.utils.tensorboard import SummaryWriter\n","from tqdm.notebook import tqdm\n","\n","base_path = Path('')\n","input_path = base_path / 'input'\n","data_path = base_path / 'data'\n","plot_path = base_path / 'plots'\n","model_path = base_path / 'models'\n","Path.mkdir(data_path, exist_ok=True)\n","Path.mkdir(plot_path, exist_ok=True)\n","Path.mkdir(model_path, exist_ok=True)\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["should_fit = True\n","\n","time_delta_scaler, pressure_scaler = MinMaxScaler(), MinMaxScaler()\n","\n","df = pd.read_csv(input_path / 'train.csv')\n","df = df.copy()\n","# Remove the expiration phase\n","df = df[df['u_out'] == 0].drop(columns='u_out')\n","\n","# Adding time_delta\n","df['time_delta'] = df['time_step'] - df.groupby('breath_id')['time_step'].shift(1)\n","df['time_delta'] = df['time_delta'].clip(upper=0.04) # some time_delta are really huge, probably capping them is a good idea\n","df['time_delta'] = df['time_delta'].fillna(df['time_delta'].mean()) # set first time-delta as mean\n","\n","if should_fit:\n","    # Prepare for rescaling. should be done only on training, but meh.\n","    time_delta_scaler.fit(df['time_delta'].values.reshape(-1, 1))\n","    pressure_scaler.fit(df['pressure'].values.reshape(-1, 1))\n","\n","# Scaling\n","df['time_delta'] = time_delta_scaler.transform(df[['time_delta']].values)\n","if 'pressure' in df:\n","    df['pressure'] = pressure_scaler.transform(df[['pressure']].values)\n","else:\n","    df['pressure'] = 0\n","df['u_in'] = df['u_in'] / 100\n","df['R'] = df['R'].map({5:0, 20:0.5, 50:1})\n","df['C'] = df['C'].map({10:0, 20:0.5, 50:1})"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>breath_id</th>\n","      <th>R</th>\n","      <th>C</th>\n","      <th>time_step</th>\n","      <th>u_in</th>\n","      <th>pressure</th>\n","      <th>time_delta</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.000000</td>\n","      <td>0.000833</td>\n","      <td>0.115911</td>\n","      <td>0.187894</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.033652</td>\n","      <td>0.183830</td>\n","      <td>0.116965</td>\n","      <td>0.258445</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.067514</td>\n","      <td>0.225093</td>\n","      <td>0.146470</td>\n","      <td>0.282956</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.101542</td>\n","      <td>0.228088</td>\n","      <td>0.204426</td>\n","      <td>0.302313</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>0.5</td>\n","      <td>1.0</td>\n","      <td>0.135756</td>\n","      <td>0.253559</td>\n","      <td>0.211802</td>\n","      <td>0.323983</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6035945</th>\n","      <td>6035946</td>\n","      <td>125749</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.834147</td>\n","      <td>0.018694</td>\n","      <td>0.469968</td>\n","      <td>0.231456</td>\n","    </tr>\n","    <tr>\n","      <th>6035946</th>\n","      <td>6035947</td>\n","      <td>125749</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.867574</td>\n","      <td>0.021544</td>\n","      <td>0.464700</td>\n","      <td>0.232097</td>\n","    </tr>\n","    <tr>\n","      <th>6035947</th>\n","      <td>6035948</td>\n","      <td>125749</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.900917</td>\n","      <td>0.013044</td>\n","      <td>0.476291</td>\n","      <td>0.222348</td>\n","    </tr>\n","    <tr>\n","      <th>6035948</th>\n","      <td>6035949</td>\n","      <td>125749</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.934309</td>\n","      <td>0.017338</td>\n","      <td>0.468915</td>\n","      <td>0.227974</td>\n","    </tr>\n","    <tr>\n","      <th>6035949</th>\n","      <td>6035950</td>\n","      <td>125749</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.967743</td>\n","      <td>0.009587</td>\n","      <td>0.479452</td>\n","      <td>0.232932</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2290968 rows Ã— 8 columns</p>\n","</div>"],"text/plain":["              id  breath_id    R    C  time_step      u_in  pressure  \\\n","0              1          1  0.5  1.0   0.000000  0.000833  0.115911   \n","1              2          1  0.5  1.0   0.033652  0.183830  0.116965   \n","2              3          1  0.5  1.0   0.067514  0.225093  0.146470   \n","3              4          1  0.5  1.0   0.101542  0.228088  0.204426   \n","4              5          1  0.5  1.0   0.135756  0.253559  0.211802   \n","...          ...        ...  ...  ...        ...       ...       ...   \n","6035945  6035946     125749  1.0  0.0   0.834147  0.018694  0.469968   \n","6035946  6035947     125749  1.0  0.0   0.867574  0.021544  0.464700   \n","6035947  6035948     125749  1.0  0.0   0.900917  0.013044  0.476291   \n","6035948  6035949     125749  1.0  0.0   0.934309  0.017338  0.468915   \n","6035949  6035950     125749  1.0  0.0   0.967743  0.009587  0.479452   \n","\n","         time_delta  \n","0          0.187894  \n","1          0.258445  \n","2          0.282956  \n","3          0.302313  \n","4          0.323983  \n","...             ...  \n","6035945    0.231456  \n","6035946    0.232097  \n","6035947    0.222348  \n","6035948    0.227974  \n","6035949    0.232932  \n","\n","[2290968 rows x 8 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:25:33.586578Z","iopub.status.busy":"2021-10-11T15:25:33.586006Z","iopub.status.idle":"2021-10-11T15:26:41.630434Z","shell.execute_reply":"2021-10-11T15:26:41.629734Z","shell.execute_reply.started":"2021-10-11T15:25:33.586517Z"},"trusted":true},"outputs":[],"source":["def flatten_df(df, time_delta_scaler, pressure_scaler, should_fit):\n","    # Remove the expiration phase\n","    df = df[((df['id'] - 1) % 80) < 32].copy()\n","\n","    # adding time_delta\n","    df['time_delta'] = df['time_step'] - df.groupby('breath_id')['time_step'].shift(1)\n","    df['time_delta'] = df['time_delta'].clip(upper=0.04) # some time_delta are really huge, probably capping them is a good idea\n","    df['time_delta'] = df['time_delta'].fillna(df['time_delta'].mean()) # set first time-delta as mean\n","\n","    if should_fit:\n","        # Prepare for rescaling. should be done only on training, but meh.\n","        time_delta_scaler.fit(df['time_delta'].values.reshape(-1, 1))\n","        pressure_scaler.fit(df['pressure'].values.reshape(-1, 1))\n","\n","    # Scaling\n","    df['time_delta'] = time_delta_scaler.transform(df[['time_delta']].values)\n","    if 'pressure' in df:\n","        df['pressure'] = pressure_scaler.transform(df[['pressure']].values)\n","    else:\n","        df['pressure'] = 0\n","    df['u_in'] = df['u_in'] / 100\n","    df['R'] = df['R'].map({5:0, 20:0.5, 50:1})\n","    df['C'] = df['C'].map({10:0, 20:0.5, 50:1})\n","\n","    # Transpose\n","    pressure_df = df.groupby('breath_id')['pressure'].apply(lambda dff: dff.reset_index(drop=True)).unstack()\n","\n","    R_C = df.groupby('breath_id')[['R', 'C']].mean()\n","    time_out = df[df['u_out'] == 0].groupby('breath_id')[['time_step', 'id']].max()\n","    time_out['id'] = (time_out['id'] - 1) % 80 + 1\n","\n","    df = df.groupby('breath_id')[['u_in', 'time_delta']].apply(lambda dff: dff.reset_index(drop=True)).unstack()\n","    df['R'] = R_C['R']\n","    df['C'] = R_C['C']\n","    df['index_out'] = time_out['id']\n","    return df.reset_index(), pressure_df.reset_index()\n","\n","\n","time_delta_scaler, pressure_scaler = MinMaxScaler(), MinMaxScaler()\n","\n","df = pd.read_csv(input_path / 'train.csv')\n","df, pressure_df = flatten_df(df, time_delta_scaler, pressure_scaler, should_fit=True)\n","\n","df_test = pd.read_csv(input_path / 'test.csv')\n","df_test, pressure_test = flatten_df(df_test, time_delta_scaler, pressure_scaler, should_fit=False)"]},{"cell_type":"markdown","metadata":{},"source":["## Clustering"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:26:41.632236Z","iopub.status.busy":"2021-10-11T15:26:41.631988Z","iopub.status.idle":"2021-10-11T15:26:49.726503Z","shell.execute_reply":"2021-10-11T15:26:49.725866Z","shell.execute_reply.started":"2021-10-11T15:26:41.632201Z"},"trusted":true},"outputs":[],"source":["n_clusters = 20\n","clustering = KMeans(n_clusters=n_clusters, random_state=0).fit(df['u_in']) # doesn't work well\n","df['cluster'] = clustering.predict(df['u_in'])\n","df_test['cluster'] = clustering.predict(df_test['u_in'])\n","#dff = df.sample(10000)\n","#clustering = DBSCAN().fit(dff['u_in'])\n","#dff['cluster'] = clustering.labels_\n","#dff['cluster'] +=1"]},{"cell_type":"markdown","metadata":{},"source":["## Train Validation split"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:26:49.728297Z","iopub.status.busy":"2021-10-11T15:26:49.727754Z","iopub.status.idle":"2021-10-11T15:26:50.534770Z","shell.execute_reply":"2021-10-11T15:26:50.533993Z","shell.execute_reply.started":"2021-10-11T15:26:49.728257Z"},"trusted":true},"outputs":[],"source":["df_train, df_valid, pressure_train, pressure_valid = train_test_split(df, pressure_df, stratify=df[['cluster']], test_size=0.2, random_state=0)\n","\n","for dff in [df_train, pressure_train, df_valid, pressure_valid]:\n","    dff.index = dff['breath_id'].values\n","    dff.sort_index(inplace=True)\n","\n","with open(data_path / 'flat_train.pickle', 'wb') as handle:\n","    pickle.dump((df_train, pressure_train), handle)\n","with open(data_path / 'flat_valid.pickle', 'wb') as handle:\n","    pickle.dump((df_valid, pressure_valid), handle)\n","with open(data_path / 'flat_test.pickle', 'wb') as handle:\n","    pickle.dump((df_test, pressure_test), handle)\n","with open(data_path / 'reverse_transform.pickle', 'wb') as handle:\n","    pickle.dump((time_delta_scaler, pressure_scaler), handle)"]},{"cell_type":"markdown","metadata":{},"source":["# Data Exploration"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:26:50.537423Z","iopub.status.busy":"2021-10-11T15:26:50.536935Z","iopub.status.idle":"2021-10-11T15:26:50.568864Z","shell.execute_reply":"2021-10-11T15:26:50.568249Z","shell.execute_reply.started":"2021-10-11T15:26:50.537385Z"},"trusted":true},"outputs":[],"source":["with open(data_path / 'flat_train.pickle', 'rb') as handle:\n","    df, pressures = pickle.load(handle)"]},{"cell_type":"markdown","metadata":{},"source":["## Time Deltas"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:26:50.570771Z","iopub.status.busy":"2021-10-11T15:26:50.570261Z","iopub.status.idle":"2021-10-11T15:26:50.574568Z","shell.execute_reply":"2021-10-11T15:26:50.573651Z","shell.execute_reply.started":"2021-10-11T15:26:50.570724Z"},"trusted":true},"outputs":[],"source":["# fig = go.Figure()\n","# fig.add_trace(go.Histogram(x=time_deltas, nbinsx=500))\n","# fig.write_html(plot_path / 'timedeltas.html') # That's a pretty weird distribution"]},{"cell_type":"markdown","metadata":{},"source":["## Clustering"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:26:50.576376Z","iopub.status.busy":"2021-10-11T15:26:50.575913Z","iopub.status.idle":"2021-10-11T15:26:50.624137Z","shell.execute_reply":"2021-10-11T15:26:50.623561Z","shell.execute_reply.started":"2021-10-11T15:26:50.576348Z"},"trusted":true},"outputs":[],"source":["# R and C stratification\n","display(df[['R', 'C']].value_counts(normalize=True).unstack())\n","display(df_test[['R', 'C']].value_counts(normalize=True).unstack())"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:26:50.626049Z","iopub.status.busy":"2021-10-11T15:26:50.625522Z","iopub.status.idle":"2021-10-11T15:27:17.413394Z","shell.execute_reply":"2021-10-11T15:27:17.412618Z","shell.execute_reply.started":"2021-10-11T15:26:50.626010Z"},"trusted":true},"outputs":[],"source":["# Plot clustering PCA\n","reduced = PCA(n_components=2).fit_transform(df['u_in'])\n","\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(\n","    x=reduced[:,0], y=reduced[:,1], marker_color=df['cluster'], mode='markers'\n","))\n","fig.write_html(plot_path / 'clustering_DBSCAN_pca.html')\n","\n","# Plot clustering breath profiles\n","fig = make_subplots(rows=5, cols=4,\n","    subplot_titles=[f'Cluster {cluster} N={size}' for cluster, size in df['cluster'].value_counts().sort_index().iteritems()]\n",")\n","for cluster in tqdm(df['cluster'].sort_values().unique()):\n","    dff = df[df['cluster'] == cluster]\n","    dff = dff.sample(n=min(400, len(dff))) # draw 400 traces for each cluster\n","    for _, row in dff.iterrows():\n","        u_in = row['u_in']\n","        times = pd.DataFrame(row['time_delta'])\n","        times = np.cumsum(time_delta_scaler.inverse_transform(times))\n","        fig.add_trace(\n","            go.Scatter(x=times, y=u_in, opacity=0.05, marker={'color': '#0000FF'}),\n","            row=cluster//4+1, col=cluster%4+1\n","        )\n","fig.update_layout(\n","    showlegend=False,\n",")\n","fig.write_html(plot_path / 'clustering_DBSCAN_traces.html')"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:27:17.415185Z","iopub.status.busy":"2021-10-11T15:27:17.414823Z","iopub.status.idle":"2021-10-11T15:27:17.448257Z","shell.execute_reply":"2021-10-11T15:27:17.447553Z","shell.execute_reply.started":"2021-10-11T15:27:17.415148Z"},"trusted":true},"outputs":[],"source":["pd.DataFrame({\n","    'train': df[['cluster', 'breath_id']].groupby('cluster').count().breath_id / len(df),\n","    'test': df_test[['cluster', 'breath_id']].groupby('cluster').count().breath_id / len(df_test),\n","}) *100"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:27:17.450231Z","iopub.status.busy":"2021-10-11T15:27:17.449692Z","iopub.status.idle":"2021-10-11T15:27:17.485314Z","shell.execute_reply":"2021-10-11T15:27:17.484625Z","shell.execute_reply.started":"2021-10-11T15:27:17.450192Z"},"trusted":true},"outputs":[],"source":["dff = df.sample(2000)\n","fig = go.Figure()\n","fig.add_trace(go.Scatter(x=dff['breath_id'], y=dff['R'], mode='markers'))\n","fig.add_trace(go.Scatter(x=dff['breath_id'], y=dff['C'] + 2, mode='markers'))\n","fig.add_trace(go.Scatter(x=dff['breath_id'], y=dff['cluster'] + 4, mode='markers'))\n","fig.write_html('plots/breath_id_R_C_clusters.html') # R, C and clusters are randomly distributed, no id hacking possible"]},{"cell_type":"markdown","metadata":{},"source":["# Pressure Prediction"]},{"cell_type":"markdown","metadata":{},"source":["## Pytorch Preparation"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:36:03.453252Z","iopub.status.busy":"2021-10-11T15:36:03.452984Z","iopub.status.idle":"2021-10-11T15:36:03.578208Z","shell.execute_reply":"2021-10-11T15:36:03.577271Z","shell.execute_reply.started":"2021-10-11T15:36:03.453224Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Using cpu device\n"]}],"source":["class SequencesDataset(Dataset):\n","    def __init__(self, df_path):\n","        with open(df_path, 'rb') as handle:\n","            df, pressures = pickle.load(handle)\n","        self.X = df[['u_in', 'time_delta', 'R', 'C']].values\n","        self.Y = pressures.drop(columns='breath_id').values\n","        for index in range(7):\n","            df[index] = (df['index_out'] > (25 + index)).astype(int)\n","        self.extra = df[['breath_id', 'index_out', 'cluster'] + list(range(7))].values\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        return torch.Tensor(self.X[idx]).to(device), torch.Tensor(self.Y[idx]).to(device), torch.Tensor(self.extra[idx]).to(device)\n","\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","print('Using {} device'.format(device))\n","\n","train_data = SequencesDataset(data_path / 'flat_train.pickle')\n","train_dataloader = DataLoader(train_data, batch_size=64, shuffle=True)\n","\n","valid_data = SequencesDataset(data_path / 'flat_valid.pickle')\n","valid_dataloader = DataLoader(valid_data, batch_size=64, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["## Model Definition"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:36:04.848189Z","iopub.status.busy":"2021-10-11T15:36:04.847927Z","iopub.status.idle":"2021-10-11T15:36:04.862191Z","shell.execute_reply":"2021-10-11T15:36:04.861252Z","shell.execute_reply.started":"2021-10-11T15:36:04.848161Z"},"trusted":true},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    def __init__(self, layers_width, dropout_p):\n","        super(NeuralNetwork, self).__init__()\n","        self.linear_relu_stack = nn.Sequential(\n","            nn.Linear(66, layers_width), # 32 u_in, 32 time_delta, R, C\n","            nn.ReLU(),\n","            nn.Dropout(p=dropout_p),\n","\n","            nn.Linear(layers_width, layers_width),\n","            nn.ReLU(),\n","            nn.Dropout(p=dropout_p),\n","\n","            nn.Linear(layers_width, layers_width),\n","            nn.ReLU(),\n","            nn.Dropout(p=dropout_p),\n","\n","            nn.Linear(layers_width, layers_width),\n","            nn.ReLU(),\n","\n","            nn.Linear(layers_width, 32),\n","        )\n","\n","    def forward(self, x):\n","        logits = self.linear_relu_stack(x)\n","        return logits\n","\n","layers_width = 70\n","dropout_p = 0\n","model = NeuralNetwork(layers_width, dropout_p).to(device)\n","print(model)\n","writer = SummaryWriter('runs/dropout_0.8__width_90__height_7')\n","writer.add_graph(model, next(iter(train_dataloader))[0])"]},{"cell_type":"markdown","metadata":{},"source":["## Training"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# %load_ext tensorboard\n","# %tensorboard --logdir runs"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:36:06.145642Z","iopub.status.busy":"2021-10-11T15:36:06.145107Z","iopub.status.idle":"2021-10-11T15:36:06.152157Z","shell.execute_reply":"2021-10-11T15:36:06.151141Z","shell.execute_reply.started":"2021-10-11T15:36:06.145608Z"},"trusted":true},"outputs":[],"source":["learning_rate = 3e-4\n","batch_size = 64\n","epochs = 3000\n","\n","loss_function = nn.MSELoss(reduction='sum')\n","\n","def fixed_loss_function(Y, prediction, extra):\n","    prediction[:,-7:] *= extra[:,-7:] # put to 0 prediction during expiration phase in order to 0 their grad\n","    Y[:,-7:] *= extra[:,-7:] # put to 0 target during expiration phase in order to not increase the loss\n","    return loss_function(prediction, Y) / (extra[:,-7:].sum() + 25 * Y.shape[0]) # divide only for the number of cases in inspiration phase\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T15:36:07.094131Z","iopub.status.busy":"2021-10-11T15:36:07.093351Z","iopub.status.idle":"2021-10-11T18:29:04.753217Z","shell.execute_reply":"2021-10-11T18:29:04.751947Z","shell.execute_reply.started":"2021-10-11T15:36:07.094095Z"},"trusted":true},"outputs":[],"source":["size = len(train_dataloader.dataset)\n","min_valid_loss = 1\n","\n","for epoch in tqdm(range(epochs)):\n","    model.train()\n","    train_loss = 0\n","    for X, Y, extra in train_dataloader:\n","        prediction = model(X)\n","        loss = fixed_loss_function(prediction, Y, extra)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_loss += loss.item()\n","    \n","    model.eval()\n","    valid_loss = 0\n","    with torch.no_grad():\n","        for X, Y, extra in valid_dataloader:\n","            prediction = model(X)\n","            valid_loss += fixed_loss_function(prediction, Y, extra).item()\n","    if min_valid_loss > valid_loss / len(valid_dataloader):\n","        min_valid_loss = valid_loss / len(valid_dataloader)\n","        best_model_parameters = model.state_dict()\n","\n","    writer.add_scalars('loss/train_valid', {\n","        'train': train_loss / len(train_dataloader),\n","        'valid': valid_loss / len(valid_dataloader),\n","    }, epoch)\n","\n","model.load_state_dict(best_model_parameters)\n","torch.save(model, model_path / 'model.pth')"]},{"cell_type":"markdown","metadata":{},"source":["# Prediction Analysis"]},{"cell_type":"code","execution_count":30,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T18:32:38.758292Z","iopub.status.busy":"2021-10-11T18:32:38.758033Z","iopub.status.idle":"2021-10-11T18:32:40.748112Z","shell.execute_reply":"2021-10-11T18:32:40.747290Z","shell.execute_reply.started":"2021-10-11T18:32:38.758262Z"},"trusted":true},"outputs":[],"source":["with open(data_path / 'reverse_transform.pickle', 'rb') as handle:\n","    time_delta_scaler, pressure_delta_scaler = pickle.load(handle)\n","valid_final_dataloader = DataLoader(valid_data, batch_size=len(valid_data), shuffle=False)\n","metric_function = nn.L1Loss(reduction='none')\n","\n","model.eval()\n","with torch.no_grad():\n","    X, Y, extra = next(iter(valid_final_dataloader))\n","    prediction = model(X)\n","    full_metric = metric_function(prediction, Y).cpu().numpy() * pressure_delta_scaler.data_range_.item()\n","X = X.cpu().numpy()\n","extra = extra.cpu().numpy()\n","full_metric[:,-7:][extra[:,-7:] == 0] = np.nan\n","full_metric = pd.DataFrame(full_metric, index=extra[:,0])\n","valid_error = full_metric.sum().sum() / full_metric.notna().sum().sum()\n","print(f'Error on validation: {valid_error}')\n","\n","R_C_cluster = pd.DataFrame({'R': X[:,-2], 'C': X[:,-1], 'cluster': extra[:,2]}, index=extra[:,0])"]},{"cell_type":"markdown","metadata":{},"source":["## Error by R C"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2021-10-11T18:35:37.541636Z","iopub.status.busy":"2021-10-11T18:35:37.541360Z","iopub.status.idle":"2021-10-11T18:35:37.700861Z","shell.execute_reply":"2021-10-11T18:35:37.700216Z","shell.execute_reply.started":"2021-10-11T18:35:37.541605Z"},"trusted":true},"outputs":[],"source":["fig = make_subplots(rows=3, cols=3, subplot_titles=[f'R={R} C={C}' for R in [0, 0.5, 1] for C in [0, 0.5, 1]])\n","for R in [0, 0.5, 1]:\n","    for C in [0, 0.5, 1]:\n","        filtered_metric = full_metric[(R_C_cluster['R'] == R) & (R_C_cluster['C'] == C)]\n","        fig.add_trace(\n","            go.Scatter(y=filtered_metric.mean()),\n","            row=int(R*2+1), col=int(C*2+1)\n","        )\n","fig.update_layout(height=600, margin={'t':30, 'l':30, 'b':30, 'r':30}, showlegend=False)\n","fig"]},{"cell_type":"markdown","metadata":{},"source":["## Error by Cluster"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig = make_subplots(rows=5, cols=4,\n","    subplot_titles=[f'Cluster {int(cluster)} N={size}' for cluster, size in R_C_cluster['cluster'].value_counts().sort_index().iteritems()]\n",")\n","for cluster in R_C_cluster['cluster'].sort_values().unique():\n","    cluster = int(cluster)\n","    filtered_metric = full_metric[R_C_cluster['cluster'] == cluster]\n","    fig.add_trace(\n","        go.Scatter(y=filtered_metric.mean()),\n","        row=cluster//4+1, col=cluster%4+1\n","    )\n","fig.update_layout(height=600, margin={'t':30, 'l':30, 'b':30, 'r':30}, showlegend=False)\n","fig"]},{"cell_type":"markdown","metadata":{},"source":["## Plot single Breath"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with open('output/flat_valid.pickle', 'rb') as handle:\n","    dff, pressures = pickle.load(handle)\n","\n","def plot_breath(breath_id, df, pressures, prediction=None):\n","    df.index = df['breath_id']\n","    pressures.index = pressures['breath_id']\n","    row = df.loc[breath_id]\n","    u_in = row['u_in']\n","    times = pd.DataFrame(row['time_delta'])\n","    times = np.cumsum(time_delta_scaler.inverse_transform(times))\n","    pressures = pressures.loc[breath_id][1:]\n","    prediction = prediction[0].numpy()\n","    fig = go.Figure()\n","    fig.add_trace(go.Scatter(\n","        x=times, y=u_in, opacity=0.5, marker={'color': '#0000FF'}, name='u_in', mode='lines+markers'\n","    ))\n","    fig.add_vline(x=times[int(row['index_out'])-1].item())\n","    fig.add_trace(go.Scatter(\n","        x=times, y=prediction, opacity=0.5, marker={'color': '#FF3333'}, name='prediction', mode='lines+markers'\n","    ))\n","    fig.add_trace(go.Scatter(\n","        x=times, y=pressures, opacity=0.7, marker={'color': 'red'}, name='target', mode='lines+markers'\n","    ))\n","    fig.update_layout(\n","        hovermode='x unified',\n","        title=f\"breath_id: {row['breath_id'].item()} R={row['R'].item()} C={row['C'].item()}\"\n","    )\n","    return fig\n","\n","\n","plot_breath(dff.index[6], dff, pressures, prediction)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["writer.close()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Old Visualization"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def plot_breath(df, breath_index, prediction=None):\n","    fig = go.Figure()\n","    df['prediction'] = prediction\n","    one = df[df['breath_id'] == breath_index]\n","    fig.add_trace(go.Scatter(\n","        x=one['time_step'], y=one['u_in'], opacity=0.5, marker={'color': '#0000FF'}, name='u_in', mode='lines+markers'\n","    ))\n","    fig.add_trace(go.Scatter(\n","        x=one['time_step'], y=one['u_out']*20, opacity=0.5, marker={'color': 'green'}, name='u_out', mode='lines+markers'\n","    ))\n","    fig.add_trace(go.Scatter(\n","        x=one['time_step'], y=one['prediction'], opacity=0.5, marker={'color': '#FF3333'}, name='prediction', mode='lines+markers'\n","    ))\n","    fig.add_trace(go.Scatter(\n","        x=one['time_step'], y=one['pressure'], opacity=0.7, marker={'color': 'red'}, name='target', mode='lines+markers'\n","    ))\n","    fig.update_layout(\n","        hovermode='x unified',\n","        title=f\"Breath ID: {breath_index} R={one['R'].iloc[0]} C={one['C'].iloc[0]}\"\n","    )\n","    return fig\n","\n","metrics = _\n","breath_index = df_valid['breath_id'].unique()[0]\n","\n","# breath_index = metrics.index[-500]\n","# fig = plot_breath(df_valid, breath_index)\n","fig = plot_breath(df_train, 4)\n","fig.show()\n","# weird breaths:\n","# - long time-delta: 24127, 55851, 72104\n","# - negative pressure: 542, 77803, 112036, 45099"]},{"cell_type":"markdown","metadata":{},"source":["# Test"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Load data and model\n","with open('output/reverse_transform.pickle', 'rb') as handle:\n","    _, pressure_scaler = pickle.load(handle)\n","test_data = SequencesDataset('output/flat_test.pickle')\n","test_dataloader = DataLoader(test_data, batch_size=len(test_data), shuffle=False)\n","model = torch.load('output/model.pth')\n","\n","# Compute predictions\n","with torch.no_grad():\n","    X, Y, extra = next(iter(test_dataloader))\n","    prediction = model(X)\n","\n","# Inverse preprocessing to reconstruct pressure column\n","pressures = pd.DataFrame(prediction.numpy())\n","for index in range(32, 80):\n","    pressures[index] = 0\n","pressures = pressures.transpose()\n","pressures = pd.concat([pressures[column] for column in pressures])\n","pressures = pressure_scaler.inverse_transform(pd.DataFrame(pressures))\n","submission = pd.DataFrame({'id': range(1, len(pressures) + 1), 'pressure': pressures[:,0]})\n","\n","# Save submission as .csv and .gz\n","submission.to_csv('output/submission.csv', index=False)\n","with open('output/submission.csv', 'rb') as handle:\n","    text = handle.read()\n","with gzip.open('output/submission.gz', 'wb') as handle:\n","    handle.write(text)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"},"kernelspec":{"display_name":"Python 3.8.10 64-bit","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":4}
